{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Libraries required for Dr Rob Collins' Machine Learning Course\n",
    "\n",
    "Dr Rob Collins\n",
    "\n",
    "Version 8, 18th August 2021\n",
    "\n",
    "(c) Donox Ltd 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lists the libraries required for each session. If you can run every code block within each session without an error showing, then you have the required libraries installed within your environment.\n",
    "\n",
    "__Note__ that libraries are only listed once in this list. Thus, for example, if the libraries used in sessino 1 are then re-used in the Session 4 tutorial I do not re-list them. Many of the libraries that are introduced early in the course are re-used later in the course. You should therefore check that you have access to all of these libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 0 : Python Re-fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1 : Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                   # Allows easy creation and management\n",
    "                                # of dataframes (data tables). \n",
    "                                # See https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                    # Powerful functions for numerical\n",
    "                                # computation. See https://numpy.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns           # Statistical data visualisation. \n",
    "                                # See http://seaborn.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib               # Data plotting library. \n",
    "                                # See https://matplotlib.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno    # Library to visualise missing data.\n",
    "                    # See https://github.com/ResidentMario/missingno \n",
    "    # Install using:  conda install -c conda-forge missingno "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2 : End-to-end example of supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn        # A powerful and extensive Machine\n",
    "                      # Learning library. \n",
    "                      # See https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle         # Enables saving and loading of models to binary files\n",
    "                      # Useful when it takes a long time to build a model .. which can\n",
    "                      # then be saved and re-used at a later date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3a : Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_toolkits             # A simple 3D plotting library\n",
    "                                # extension to matplotlib. \n",
    "            # See https://matplotlib.org/2.2.2/mpl_toolkits/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3b : Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand           # Enables generation of random numbers\n",
    "                                # with a variety of distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 4a : Matricies and Linear Algebra\n",
    "All required libraries are allready included in the above list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 4b : Probability and Distributions\n",
    "All required libraries are allready included in the above list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 5 : Gradient descent\n",
    "All required libraries are allready included in the above list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 6 : Polynomial regression and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to be able to access the following data-set. Please tell me if you cannot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# boston_dataset = load_boston()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "# alternative dataset 1\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# alternative dataset 2\n",
    "from sklearn.datasets import fetch_openml\n",
    "housing = fetch_openml(name=\"house_prices\", as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 7 : Trees and Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this workshop we will be generating pictures of decision trees. You will have to instal the 'Graphviz' tool onto your computer to generate those images:\n",
    "\n",
    "https://graphviz.org/\n",
    "\n",
    "Other required libraries are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 8 : Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Wordcloud\n",
    "The 'wordcloud' library was not part of my Anaconda environment. I thus had to instal this libary using the command:\n",
    "\n",
    "conda install -c conda-forge wordcloud \n",
    "\n",
    "Details of this can be found here: \n",
    "https://anaconda.org/conda-forge/wordcloud and here: https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Natural Language Toolkit (NLTK)\n",
    "This workshop makes extensive use of the 'Natural Language Toolkit (NLTK). You can read more about NLTK here:\n",
    "https://www.nltk.org/\n",
    "\n",
    "If NLTK is not part of the basic instal of your Anaconda, then you can find out how to instal it here: https://anaconda.org/anaconda/nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus.reader import tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Vader Sentiment Analayzer\n",
    "https://anaconda.org/conda-forge/vadersentiment\n",
    "\n",
    "conda install -c conda-forge vadersentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Other libraries used in the Natural Language Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 9 : Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Keras\n",
    "Since keras is not part of the base instal within Anaconda, I had to first update my environment to instal it. Thus, if you are using Anaconda you may need to open a terminal window and instal keras using the command:\n",
    "\n",
    "conda install -c conda-forge keras \n",
    "\n",
    "Which is described here:https://anaconda.org/conda-forge/keras \n",
    "\n",
    "I have a high-power gpu on my computer which makes processing much faster and thus I used this alternate command:\n",
    "\n",
    "conda install -c anaconda keras-gpu \n",
    "\n",
    "Which is described at https://anaconda.org/anaconda/keras-gpu\n",
    "\n",
    "This website provides a useful tutorial on how to instal tensorflow and keras: https://www.innovationmerge.com/2020/12/21/Install-TensorFlow-and-Keras-on-GPU-using-Anaconda-Navigator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout \n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 10 : Reinforcement Learning\n",
    "\n",
    "AI Gym can be installed in the Anaconda Envionment using the command:\n",
    "\n",
    "    conda install -c conda-forge gym \n",
    "    \n",
    "Required libraries are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython.display import clear_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
